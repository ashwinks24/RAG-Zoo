# -*- coding: utf-8 -*-
"""test_doc_relevance_evaluator.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YtA0ZPZATiQBWPVoKuhzdCCBRROQDcAQ
"""

import pytest
from unittest.mock import MagicMock
from rag_src.evaluator.doc_relevance_evaluator import RelevanceEvaluator

@pytest.fixture
def mock_llm():
    llm = MagicMock()
    llm.generate.return_value = "0.85"
    return llm

def test_relevance_evaluator_score_above_threshold(mock_llm):
    evaluator = RelevanceEvaluator(llm=mock_llm, threshold=0.7)

    query = "What is a rocket?"
    response = "A rocket is a space vehicle."
    contexts = [
        "A rocket launches into space.",
        "It carries satellites and astronauts."
    ]

    result = evaluator.evaluate(query, response, contexts)

    assert result["relevance_score"] == 0.85
    assert result["above_threshold"] is True
    mock_llm.generate.assert_called_once()